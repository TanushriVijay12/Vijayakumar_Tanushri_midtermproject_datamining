{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e4afb0-7d6d-4e64-9b3b-9ef635ce7afd",
   "metadata": {},
   "source": [
    "# CS634 Midterm Project\n",
    "**Student:** Tanushri Vijayakumar  \n",
    "**Instructor:** Dr. Yasser Abdullah  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb67942c-b844-4d49-8866-e48f4895248a",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook implements and compares three methods for **Association Rule Mining**:  \n",
    "\n",
    "1. **Brute Force (custom implementation)**  \n",
    "2. **Apriori (using Python library mlxtend)**  \n",
    "3. **FP-Growth (using Python library mlxtend)**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787ab4f0-8304-4fa5-b30f-8e39c90851a1",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Import all required Python libraries:\n",
    "\n",
    "**os**: Used to handle file paths (locating datasets inside the folder).  \n",
    "**pandas (pd)**: For working with transaction data in a tabular DataFrame format.  \n",
    "**time**: To compare runtime\n",
    "**mlxtend.frequent_patterns**: Contains built-in implementations of: \n",
    "- **apriori**: to run the Apriori algorithm.\n",
    "- **fpgrowth**: to run the FP-Growth algorithm.\n",
    "- **association_rules**: to generate rules from frequent itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64c2530-d0e2-454a-840e-5e39f36b9570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e8a469-7ce0-4447-ac65-13cdac702212",
   "metadata": {},
   "source": [
    "## 2. Dataset Selection\n",
    "\n",
    "We are working with transaction datasets representing customer purchases at 5 different stores (Amazon, BestBuy, Walmart, Nike, and Wholefoods.\n",
    "\n",
    "The user is prompted to:\n",
    "- Select a dataset\n",
    "- Specify minimum support and confidence thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c04e247-0dd3-4c8f-ada5-778b5e9e5a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVAILABLE DATASETS:\n",
      "1. amazon_transactions.csv\n",
      "2. bestbuy_transactions.csv\n",
      "3. walmart_transactions.csv\n",
      "4. nike_transactions.csv\n",
      "5. wholefoods_transactions.csv\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the dataset number to choose which dataset to use:  4\n",
      "Enter the minimum support threshold (0-1):  0.4\n",
      "Enter the minimum confidence threshold (0-1):  0.5\n"
     ]
    }
   ],
   "source": [
    "# 1. Transaction database\n",
    "datasets = {1: \"amazon_transactions.csv\",2: \"bestbuy_transactions.csv\", 3: \"walmart_transactions.csv\",4: \"nike_transactions.csv\",5: \"wholefoods_transactions.csv\"}\n",
    "print(\"AVAILABLE DATASETS:\")\n",
    "\n",
    "for i, ds in datasets.items():\n",
    "    print(f\"{i}. {ds}\")\n",
    "print(\"\\n\")    \n",
    "\n",
    "data_select  = int(input(\"Enter the dataset number to choose which dataset to use: \"))\n",
    "if data_select not in datasets:\n",
    "    print(\"Invalid selection\")\n",
    "    exit()\n",
    "\n",
    "filename = os.path.join(\"..\", \"dataset\", datasets[data_select])\n",
    "\n",
    "min_sup = float(input(\"Enter the minimum support threshold (0-1): \"))\n",
    "min_conf = float(input(\"Enter the minimum confidence threshold (0-1): \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f59dd-7079-488e-a66c-06fef67240b7",
   "metadata": {},
   "source": [
    "## 3. Brute Force Implementation\n",
    "\n",
    "The brute force method generates all possible item combinations and calculates their support by scanning the transactions.  \n",
    "- **Ck (Candidate Itemsets):** All possible combinations of items of size k.  \n",
    "- **Lk (Frequent Itemsets):** Subset of Ck that meets the support threshold.  \n",
    "\n",
    "This process continues until no more frequent itemsets are found.  \n",
    "\n",
    "Finally, association rules are generated by splitting itemsets into antecedent-consequent pairs and calculating confidence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc4f7a-d8c5-4bb1-91c1-b77f42634f95",
   "metadata": {},
   "source": [
    "### Steps\n",
    "1. Load dataset.  \n",
    "2. Generate all candidate sets Ck.  \n",
    "3. Prune candidates to get frequent sets Lk.  \n",
    "4. Repeat for larger k.  \n",
    "5. Generate rules with sufficient confidence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a6251f-7793-42c9-b2ef-5fd6e442edd3",
   "metadata": {},
   "source": [
    "#### Load transactions from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaeeb4dd-7dfa-437e-bb5d-8510476df7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transactions(filename):    \n",
    "    transactions = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        next(f)  # skip header\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            items = [p.strip() for p in parts[3:]]  # items start from 4th column\n",
    "            transactions.append(items)\n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48de51fa-b20f-4285-9653-46b5c3e5ce07",
   "metadata": {},
   "source": [
    "#### Generate candidate itemsets of size k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a07d9500-c0e2-49d3-895d-2f737adc1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates(items, k):\n",
    "    candidates = []\n",
    "    n = len(items)\n",
    "    items = list(items)\n",
    "\n",
    "    def helper(start, comb):\n",
    "        if len(comb) == k:\n",
    "            candidates.append(comb[:])\n",
    "            return\n",
    "        for i in range(start, n):\n",
    "            comb.append(items[i])\n",
    "            helper(i+1, comb)\n",
    "            comb.pop()\n",
    "\n",
    "    helper(0, [])\n",
    "    return candidates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770be163-4dff-4288-b55c-21fe5797c1e0",
   "metadata": {},
   "source": [
    "#### Calculate support of an itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fa22c2c-2c34-4040-b3e8-d9d2bee8b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_transactions(transactions, item):\n",
    "    count = 0\n",
    "    for t in transactions:\n",
    "        if all(i in t for i in item):\n",
    "            count += 1\n",
    "    return count / len(transactions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0004883f-71c3-4cf5-972c-28e26617e0e1",
   "metadata": {},
   "source": [
    "#### Generate all frequent itemsets Lk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7b02b42-c3c6-4631-b2f0-00da2b6697fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequent_itemsets(transactions, min_sup):\n",
    "    unique_items = set()\n",
    "    for t in transactions:\n",
    "       for i in t:\n",
    "           unique_items.add(i)\n",
    "\n",
    "    freq_is = {}\n",
    "    k = 1\n",
    "\n",
    "    while True:\n",
    "        candidates = generate_candidates(unique_items, k)\n",
    "        valid = []\n",
    "        for c in candidates:\n",
    "            sup = support_transactions(transactions, c)\n",
    "            if sup >= min_sup:\n",
    "                valid.append((c, sup))\n",
    "        if not valid:\n",
    "            break\n",
    "        freq_is[k] = valid\n",
    "        k += 1\n",
    "\n",
    "    return freq_is\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d93a1df-72cb-4536-a0b5-cdf213547e7a",
   "metadata": {},
   "source": [
    "#### Generate all non-empty subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75cf67f6-b38f-4e54-a7b6-bd301d464932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subsets(itemset):\n",
    "    subsets = []\n",
    "\n",
    "    def helper(start, current):\n",
    "        if 0 < len(current) < len(itemset):\n",
    "            subsets.append(current[:])   # store a copy\n",
    "        for i in range(start, len(itemset)):\n",
    "            current.append(itemset[i])\n",
    "            helper(i + 1, current)\n",
    "            current.pop()\n",
    "\n",
    "    helper(0, [])\n",
    "    return subsets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec89df-96a4-429e-a7d9-5f4fb3b1a0d2",
   "metadata": {},
   "source": [
    "#### Generate association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81a27060-5c9f-4978-8d17-3bd41c14c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rules(freq_is, min_conf):\n",
    "    rules = []\n",
    "    for k in freq_is:\n",
    "        for itemset, sup in freq_is[k]:\n",
    "            if len(itemset) < 2:\n",
    "                continue\n",
    "\n",
    "            subsets = generate_subsets(itemset)\n",
    "\n",
    "            for left in subsets:\n",
    "                right = [x for x in itemset if x not in left]\n",
    "\n",
    "                # Find support of left side\n",
    "                sup_left = None\n",
    "                for size, sets in freq_is.items():\n",
    "                    if size == len(left):\n",
    "                        for c, s in sets:\n",
    "                            if set(c) == set(left):\n",
    "                                sup_left = s\n",
    "                                break\n",
    "\n",
    "                if sup_left and sup_left > 0:\n",
    "                    conf = sup / sup_left\n",
    "                    if conf >= min_conf:\n",
    "                        rules.append((left, right, sup, conf))\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc978a8-1844-44d0-b4bb-f5b36c819649",
   "metadata": {},
   "source": [
    "#### Calculate time and store in results for comparison at end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "292c1ba7-3eaf-424f-9a2e-810fb10ebb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa2f0f6-ed3e-4047-866e-df9775d95c76",
   "metadata": {},
   "source": [
    "### Brute Force Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62127ea3-fb37-4b3a-9f79-08249c6f1339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent itemsets of size 1 :\n",
      "['Sweatshirts']: 0.50\n",
      "['Socks']: 0.55\n",
      "['\"Running Shoe']: 0.70\n",
      "['Rash Guard']: 0.50\n",
      "\n",
      "Frequent itemsets of size 2 :\n",
      "['Sweatshirts', 'Socks']: 0.40\n",
      "['Sweatshirts', '\"Running Shoe']: 0.45\n",
      "['Socks', '\"Running Shoe']: 0.50\n",
      "\n",
      "Frequent itemsets of size 3 :\n",
      "['Sweatshirts', 'Socks', '\"Running Shoe']: 0.40\n",
      "\n",
      "\n",
      "Association rules:\n",
      "['Sweatshirts'] -> ['Socks']: (support: 0.40, confidence: 0.80)\n",
      "['Socks'] -> ['Sweatshirts']: (support: 0.40, confidence: 0.73)\n",
      "['Sweatshirts'] -> ['\"Running Shoe']: (support: 0.45, confidence: 0.90)\n",
      "['\"Running Shoe'] -> ['Sweatshirts']: (support: 0.45, confidence: 0.64)\n",
      "['Socks'] -> ['\"Running Shoe']: (support: 0.50, confidence: 0.91)\n",
      "['\"Running Shoe'] -> ['Socks']: (support: 0.50, confidence: 0.71)\n",
      "['Sweatshirts'] -> ['Socks', '\"Running Shoe']: (support: 0.40, confidence: 0.80)\n",
      "['Sweatshirts', 'Socks'] -> ['\"Running Shoe']: (support: 0.40, confidence: 1.00)\n",
      "['Sweatshirts', '\"Running Shoe'] -> ['Socks']: (support: 0.40, confidence: 0.89)\n",
      "['Socks'] -> ['Sweatshirts', '\"Running Shoe']: (support: 0.40, confidence: 0.73)\n",
      "['Socks', '\"Running Shoe'] -> ['Sweatshirts']: (support: 0.40, confidence: 0.80)\n",
      "['\"Running Shoe'] -> ['Sweatshirts', 'Socks']: (support: 0.40, confidence: 0.57)\n"
     ]
    }
   ],
   "source": [
    "transactions = load_transactions(filename)\n",
    "start = time.perf_counter()\n",
    "freq_is = frequent_itemsets(transactions, min_sup)\n",
    "\n",
    "# Print frequent itemsets or message if none\n",
    "if not freq_is:\n",
    "    print(\"No frequent itemsets found with the given support threshold.\")\n",
    "else:\n",
    "    for k, items in freq_is.items():\n",
    "        print(\"\\nFrequent itemsets of size\", k, \":\")\n",
    "        for item, sup in items:\n",
    "            print(f\"{item}: {sup:.2f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "rules = generate_rules(freq_is, min_conf)\n",
    "end = time.perf_counter()\n",
    "\n",
    "# Print rules or message if none\n",
    "if not rules:\n",
    "    print(\"No rules generated with the given confidence threshold.\")\n",
    "else:\n",
    "    print(\"Association rules:\")\n",
    "    for left, right, sup, conf in rules:\n",
    "        print(f\"{left} -> {right}: (support: {sup:.2f}, confidence: {conf:.2f})\")\n",
    "\n",
    "results.append([\"Brute Force\", end - start])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df3001-e4c1-4237-8d33-f7e2c239d420",
   "metadata": {},
   "source": [
    "## 4. Apriori Implementation\n",
    "The Apriori algorithm is an efficient version of the brute force method. Property: All subsets of a frequent itemset must also be frequent.\n",
    "\n",
    "This allows the algorithm to prune many candidate sets early, saving time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d128692d-f4bf-48f2-9e71-e5f0f8c049f7",
   "metadata": {},
   "source": [
    "### Steps\n",
    "1. Convert transactions into a one-hot encoded DataFrame.  \n",
    "2. Use **mlxtend.frequent_patterns.apriori** to extract frequent itemsets.  \n",
    "4. Use **association_rules** to generate rules based on minimum confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "241748ec-19d7-4d16-87b5-c1e86156f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets (Apriori):\n",
      "   support                             itemsets\n",
      "0     0.70                      (\"Running Shoe)\n",
      "1     0.50                         (Rash Guard)\n",
      "2     0.55                              (Socks)\n",
      "3     0.50                        (Sweatshirts)\n",
      "4     0.50               (\"Running Shoe, Socks)\n",
      "5     0.45         (\"Running Shoe, Sweatshirts)\n",
      "6     0.40                 (Sweatshirts, Socks)\n",
      "7     0.40  (\"Running Shoe, Sweatshirts, Socks)\n",
      "\n",
      "Association Rules (Apriori):\n",
      "                     antecedents                   consequents  support  \\\n",
      "0                (\"Running Shoe)                       (Socks)     0.50   \n",
      "1                        (Socks)               (\"Running Shoe)     0.50   \n",
      "2                (\"Running Shoe)                 (Sweatshirts)     0.45   \n",
      "3                  (Sweatshirts)               (\"Running Shoe)     0.45   \n",
      "4                  (Sweatshirts)                       (Socks)     0.40   \n",
      "5                        (Socks)                 (Sweatshirts)     0.40   \n",
      "6   (\"Running Shoe, Sweatshirts)                       (Socks)     0.40   \n",
      "7         (\"Running Shoe, Socks)                 (Sweatshirts)     0.40   \n",
      "8           (Sweatshirts, Socks)               (\"Running Shoe)     0.40   \n",
      "9                (\"Running Shoe)          (Sweatshirts, Socks)     0.40   \n",
      "10                 (Sweatshirts)        (\"Running Shoe, Socks)     0.40   \n",
      "11                       (Socks)  (\"Running Shoe, Sweatshirts)     0.40   \n",
      "\n",
      "    confidence  \n",
      "0     0.714286  \n",
      "1     0.909091  \n",
      "2     0.642857  \n",
      "3     0.900000  \n",
      "4     0.800000  \n",
      "5     0.727273  \n",
      "6     0.888889  \n",
      "7     0.800000  \n",
      "8     1.000000  \n",
      "9     0.571429  \n",
      "10    0.800000  \n",
      "11    0.727273  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(False, index=range(len(transactions)), \n",
    "                  columns=sorted(set(i for t in transactions for i in t)))\n",
    "for i, t in enumerate(transactions):\n",
    "    for item in t:\n",
    "        df.loc[i, item] = True\n",
    "\n",
    "start = time.perf_counter()\n",
    "freq_itemsets = apriori(df, min_support=min_sup, use_colnames=True)\n",
    "print(\"\\nFrequent Itemsets (Apriori):\")\n",
    "print(freq_itemsets)\n",
    "\n",
    "rules = association_rules(freq_itemsets, metric=\"confidence\", min_threshold=min_conf)\n",
    "\n",
    "end = time.perf_counter()\n",
    "results.append([\"Apriori\", end - start])\n",
    "\n",
    "print(\"\\nAssociation Rules (Apriori):\")\n",
    "print(rules[['antecedents','consequents','support','confidence']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481e51ab-4fcd-4c9e-8a70-1868baf13944",
   "metadata": {},
   "source": [
    "## 5. FP-Growth Implementation\n",
    "The FP-Growth algorithm avoids candidate generation altogether.  \n",
    "It builds a compact FP-tree structure to represent transactions and mines frequent itemsets directly from the tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b79741f-cc84-497a-a270-7e6dde1bdcf6",
   "metadata": {},
   "source": [
    "### Steps\n",
    "1. Convert transactions into a one-hot encoded DataFrame.  \n",
    "2. Use **mlxtend.frequent_patterns.fpgrowth** to extract frequent itemsets.  \n",
    "3. Use **association_rules** to generate rules.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "911c9aad-76e6-44d0-b723-1fc1fe72a240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets (FP-Growth):\n",
      "   support                             itemsets\n",
      "0     0.70                      (\"Running Shoe)\n",
      "1     0.50                         (Rash Guard)\n",
      "2     0.55                              (Socks)\n",
      "3     0.50                        (Sweatshirts)\n",
      "4     0.50               (\"Running Shoe, Socks)\n",
      "5     0.45         (\"Running Shoe, Sweatshirts)\n",
      "6     0.40                 (Sweatshirts, Socks)\n",
      "7     0.40  (\"Running Shoe, Sweatshirts, Socks)\n",
      "\n",
      "Association Rules (FP-Growth):\n",
      "                     antecedents                   consequents  support  \\\n",
      "0                (\"Running Shoe)                       (Socks)     0.50   \n",
      "1                        (Socks)               (\"Running Shoe)     0.50   \n",
      "2                (\"Running Shoe)                 (Sweatshirts)     0.45   \n",
      "3                  (Sweatshirts)               (\"Running Shoe)     0.45   \n",
      "4                  (Sweatshirts)                       (Socks)     0.40   \n",
      "5                        (Socks)                 (Sweatshirts)     0.40   \n",
      "6   (\"Running Shoe, Sweatshirts)                       (Socks)     0.40   \n",
      "7         (\"Running Shoe, Socks)                 (Sweatshirts)     0.40   \n",
      "8           (Sweatshirts, Socks)               (\"Running Shoe)     0.40   \n",
      "9                (\"Running Shoe)          (Sweatshirts, Socks)     0.40   \n",
      "10                 (Sweatshirts)        (\"Running Shoe, Socks)     0.40   \n",
      "11                       (Socks)  (\"Running Shoe, Sweatshirts)     0.40   \n",
      "\n",
      "    confidence  \n",
      "0     0.714286  \n",
      "1     0.909091  \n",
      "2     0.642857  \n",
      "3     0.900000  \n",
      "4     0.800000  \n",
      "5     0.727273  \n",
      "6     0.888889  \n",
      "7     0.800000  \n",
      "8     1.000000  \n",
      "9     0.571429  \n",
      "10    0.800000  \n",
      "11    0.727273  \n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "feq_itemsets = fpgrowth(df, min_support=min_sup, use_colnames=True)\n",
    "print(\"\\nFrequent Itemsets (FP-Growth):\")\n",
    "print(freq_itemsets)\n",
    "\n",
    "rules = association_rules(freq_itemsets, metric=\"confidence\", min_threshold=min_conf)\n",
    "\n",
    "end = time.perf_counter()\n",
    "results.append([\"FP-Growth\", end - start])\n",
    "\n",
    "print(\"\\nAssociation Rules (FP-Growth):\")\n",
    "print(rules[['antecedents','consequents','support','confidence']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3582a250-7de6-484a-a2a4-1127ed5a9db1",
   "metadata": {},
   "source": [
    "## 6. Execution time comparison\n",
    "\n",
    "To evaluate the efficiency of the three algorithms, we measured the execution time for each: Brute Force, Apriori, FP-Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79d6d8df-87f4-4868-a930-02e71bda85b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Algorithm  Execution Time (seconds)\n",
      "0  Brute Force                  0.040223\n",
      "1      Apriori                  0.046616\n",
      "2    FP-Growth                  0.010354\n"
     ]
    }
   ],
   "source": [
    "df_times = pd.DataFrame(results, columns=[\"Algorithm\", \"Execution Time (seconds)\"])\n",
    "print(df_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca607d-0779-4b7a-af86-8c939f941eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
